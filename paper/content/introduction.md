## Introduction
{:#introduction}

On top of the standard Web, which is made for humans, resides the _Semantic Web_. This extension of the Web is used by machines to interpret documents on the web and thus extract information. The Semantic Web is not just about putting data on the Web though, linking to other resources so that more data can be discovered is just as important. Tim Berners-Lee outlined the four principles of _Linked Data_ [](cite:cites bizer2011linked): (i) use URIs as names for things, (ii) use HTTP URIs so that people can look up those names, 3) when someone looks up a URI, provide useful information using standards such as Resource Description Framework [](cite:cites lassila1998resource) (RDF), and 4) include links to other URIs so that they can discover more things.

This paper will focus on a specific problem that can be solved using Linked Data. This problem involves finding a generic approach for both publishing and updating datasets. Publicly available datasets[^exmp] such as public transport schedules and parking spot availability are inherently real-time, so that even receiving an update 30 seconds too late could mean the data is already obsolete. Another example is the registry of postal addresses which may change due to the merging of municipalities. Such registries[^covid] are less volatile than the transport and parking data, but they serve the same idea. Both kinds of datasets have changes that need to become available to possible client applications -- as soon as possible, as the change indicates an invalidation of the old dataset. 

[^exmp]: https://data.gov.be/en/dataset/d4961387-23f4-44f8-b2e7-c7e9a260a83e Example dataset which counts the number of bikers on several locations in Brussels
[^covid]: https://epistat.wiv-isp.be/covid/ Belgian COVID data. This data is updated on a regular basis, but not in real-time.

Deciding the best strategy is influenced by two aspects. The first one is scalability: some technologies will inherently be more scalable than others, and these must be compared and evaluated alongside mechanisms such as caching. The second aspect is the volatility of the dataset: data that is changed often will benefit from using a streaming-based approach. These aspects have led to an increase in research interest involving Linked Data streaming <span class="comment" data-author="HD">citation needed</span>. 

In this paper, we present the state of the art regarding this subject. First, formatting of data is discussed, together with an overview of some of the RDF serialization formats. The following section considers versioning of data, namely why this is important and how to execute it. The next section discusses the delivery of data and how publishers can get their data to end-users, together with the criteria to choose an approach. Afterward, caching of data is discussed, different caching strategies for linked data are considered and compared. Finally, the last section applies all of the aforementioned subjects to the use-case of data streaming. 